{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbZcI9ZXHl3a"
      },
      "source": [
        "# Deep Q-Learning for Lunar Landing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8yPRjteXgPb"
      },
      "source": [
        "## Part 0 - Installing the required packages and importing the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slEm5teGWjWU"
      },
      "source": [
        "### Installing Gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbnq3XpoKa_7",
        "outputId": "d634f61a-d623-4fc7-dab9-62382e39686d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium) (2.2.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from gymnasium) (0.0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium==1.0.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium==1.0.0) (2.2.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium==1.0.0) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from gymnasium==1.0.0) (0.0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: swig in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (4.3.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium[box2d] in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium[box2d]) (2.2.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium[box2d]) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from gymnasium[box2d]) (4.3.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio) (2.2.5)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio) (11.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (9.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (2.19.1)\n",
            "Requirement already satisfied: stack_data in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from ipython) (5.14.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython) (0.2.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
            "Requirement already satisfied: torch in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (2.7.0+cu128)\n",
            "Requirement already satisfied: torchvision in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (0.22.0+cu128)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (2.7.0+cu128)\n",
            "Requirement already satisfied: filelock in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torch) (75.8.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torchvision) (2.2.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio[ffmpeg] in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio[ffmpeg]) (2.2.5)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio[ffmpeg]) (11.0.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from imageio[ffmpeg]) (7.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio[ffmpeg] in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio[ffmpeg]) (2.2.5)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio[ffmpeg]) (11.0.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in c:\\users\\shres\\.conda\\envs\\cuda_test\\lib\\site-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\shres\\appdata\\roaming\\python\\python312\\site-packages (from imageio[ffmpeg]) (7.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\shres\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install gymnasium==1.0.0\n",
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\"\n",
        "!pip install imageio\n",
        "!pip install ipython\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
        "!pip install \"imageio[ffmpeg]\"\n",
        "!pip install \"imageio[ffmpeg]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checking for availibility of CUDA Cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    cuda_bit = 1\n",
        "else:\n",
        "    cuda_bit = 0\n",
        "\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brqiMN3UW9T9"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mZaKXP_aMl9O"
      },
      "outputs": [],
      "source": [
        "import os #for os\n",
        "import random #for random numbers\n",
        "import numpy as np #for arrays\n",
        "import torch # to train agent w pytorch\n",
        "import torch.nn as nn #neural network module\n",
        "import torch.optim as optim # optimal module\n",
        "import torch.nn.functional as F #functions pre made for training\n",
        "import torch.autograd as autograd # for stochastic gradient descent\n",
        "from torch.autograd import Variable #training\n",
        "from collections import deque, namedtuple #training\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzlDKXvkXzGI"
      },
      "source": [
        "## Part 1 - Building the AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtG6Zc83YYy3"
      },
      "source": [
        "### Creating the architecture of the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QWpMLoF4qf-9"
      },
      "outputs": [],
      "source": [
        "class NeuNet(nn.Module): #inherits from nn.module\n",
        "\n",
        "  def __init__(self, state_size, action_size, seed=42):\n",
        "    super(NeuNet, self).__init__()\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.fc1 = nn.Linear(state_size, 128) #Input Layer\n",
        "    self.fc2 = nn.Linear(128, 128) #Hidden Layer\n",
        "    self.fc3 = nn.Linear(128, action_size) #Output Layer\n",
        "\n",
        "  def forward(self, state):\n",
        "    x = self.fc1(state)\n",
        "    x = F.relu(x) #rectifier activation function from torch.nn.functional\n",
        "    #Gone from first fully conected layer to the second\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    return self.fc3(x) #output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKr-lMG2EH9Y"
      },
      "source": [
        "\n",
        "\n",
        "*   fc1 is input layer. Number can be anything however, post testing, 64 is the most optimal in cases for lunar landings in gymnasium\n",
        "*   fc2 is hidden layer\n",
        "*   fc3 is output layer. action size is 4\n",
        "*   DEF FORWARD\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxVrBnFWZKb1"
      },
      "source": [
        "## Part 2 - Training the AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T364fz9qZb2j"
      },
      "source": [
        "### Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41sgnpCwtd5f",
        "outputId": "2aa4e61c-f53e-4990-e153-098b302c2218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State shape:  (8,)\n",
            "State size:  8\n",
            "Number of actions:  4\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\")\n",
        "state_shape = env.observation_space.shape #Vector\n",
        "state_size = env.observation_space.shape[0] #current state of env\n",
        "number_actions = env.action_space.n #Number of actions\n",
        "print('State shape: ', state_shape)\n",
        "print('State size: ', state_size)\n",
        "print('Number of actions: ', number_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_dZmOIvZgj-"
      },
      "source": [
        "### Initializing the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UuQh3LTvIKHY"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0005 #derived from experimentation\n",
        "minibatch_size = 256\n",
        "gamma = 0.99 #discount factor\n",
        "replay_buffer_size = 100000 #no. of experiences\n",
        "tau = 0.01 #Interpolation parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hD_Vs-bYnip"
      },
      "source": [
        "### Implementing Experience Replay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K932ufvF3uQM"
      },
      "outputs": [],
      "source": [
        "class ReplayMemory(object):\n",
        "\n",
        "  def __init__(self, capacity):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #if exterior device(gpu) is present. uses that hardware to process\n",
        "    self.capacity = capacity #total size of memory size\n",
        "    self.memory = [ ]\n",
        "\n",
        "  def push(self, event): #appends event and removes oldest event if memory is full\n",
        "    self.memory.append(event)\n",
        "    if len(self.memory) > self.capacity:\n",
        "      del self.memory[0]\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    exp = random.sample(self.memory, k = batch_size)\n",
        "    state = torch.from_numpy(np.vstack([e[0] for e in exp if e is not None])).float().to(self.device) #states converted to tensors and float values and send to gpu or cpu\n",
        "    action = torch.from_numpy(np.vstack([e[1] for e in exp if e is not None])).long().to(self.device) #same as states but long integers\n",
        "    rewards = torch.from_numpy(np.vstack([e[2] for e in exp if e is not None])).float().to(self.device)\n",
        "    next_state = torch.from_numpy(np.vstack([e[3] for e in exp if e is not None])).float().to(self.device)\n",
        "    dones = torch.from_numpy(np.vstack([e[4] for e in exp if e is not None]).astype(np.uint8)).float().to(self.device)\n",
        "    return state, next_state, action, rewards, dones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmEkbFbUY6Jt"
      },
      "source": [
        "### Implementing the DQN class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X4O4QC9a7wUs"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "\n",
        "  def __init__(self, state_size, action_size):\n",
        "    self.device = torch.device(\"cuda:0\" if cuda_bit==1 else \"cpu\") #if exterior device(gpu) is present. uses that hardware to process\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.local_qnetwork = NeuNet(state_size, action_size).to(self.device)\n",
        "    self.target_qnetwork = NeuNet(state_size, action_size).to(self.device)\n",
        "    self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr = learning_rate)\n",
        "    self.memory = ReplayMemory(replay_buffer_size)\n",
        "    self.t_step = 0\n",
        "\n",
        "  def step(self, state, action, reward, next_state, done):\n",
        "    self.memory.push((state, action, reward, next_state, done))\n",
        "    self.t_step = (self.t_step + 1) % 4\n",
        "    if self.t_step == 0:\n",
        "      if len(self.memory.memory) > minibatch_size: #self.memory.memory second memory is attribute. while self.memory is the instance of the memory class\n",
        "        exp_local = self.memory.sample(minibatch_size) #samples 100 experiences from the memory\n",
        "        self.learn(exp_local, gamma)\n",
        "\n",
        "  def act(self, state, epsilon = 0.):\n",
        "    state = torch.from_numpy(state).float().unsqueeze(0).to(self.device) #set as torch tensor and an extra variable to the vector to show batch number\n",
        "    self.local_qnetwork.eval()\n",
        "    with torch.no_grad():\n",
        "      action_values = self.local_qnetwork(state)\n",
        "    self.local_qnetwork.train()\n",
        "    if random.random() > epsilon: #epsilon greedy action selection policy\n",
        "      return np.argmax(action_values.cpu().data.numpy())\n",
        "    else:\n",
        "      return random.choice(np.arange(self.action_size))\n",
        "\n",
        "  def learn(self, exp, gamma):\n",
        "    states,next_states, actions, rewards, dones = exp\n",
        "    next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "    q_targets = rewards + (gamma * next_q_targets * (1 - dones))\n",
        "    q_expected = self.local_qnetwork(states).gather(1, actions)\n",
        "    loss = F.mse_loss(q_expected, q_targets)\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    self.soft_update(self.local_qnetwork, self.target_qnetwork, tau)\n",
        "\n",
        "  def soft_update(self, local_model, target_model, tau):\n",
        "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "      target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1tZElccZmf6"
      },
      "source": [
        "### Initializing the DQN agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LQHsKhwdSSA5"
      },
      "outputs": [],
      "source": [
        "agent200 = Agent(state_size, number_actions)\n",
        "agent250 = Agent(state_size, number_actions)\n",
        "agent300 = Agent(state_size, number_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8v0PtUfaVQp"
      },
      "source": [
        "### Training the DQN agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL53_97fTCFi",
        "outputId": "a2598c14-f3b3-45a2-89e3-9e5cac7c9564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode Number 100\tAverage Score: -91.17\n",
            "Episode Number 200\tAverage Score: -13.43\n",
            "Episode Number 300\tAverage Score: 81.821\n",
            "Episode Number 400\tAverage Score: 167.83\n",
            "Episode Number 439\tAverage Score: 200.42\n",
            "Environment solved in 439 episodes! Episode Number 439\tAverage Score: 200.42\n",
            "Episode 10 | Successes so far: 9cesses: 9\n",
            "Episode 20 | Successes so far: 18esses: 18\n",
            "Episode 30 | Successes so far: 28esses: 28\n",
            "Episode 40 | Successes so far: 37esses: 37\n",
            "Episode 50 | Successes so far: 45esses: 450\n",
            "Episode 60 | Successes so far: 51esses: 51\n",
            "Episode 70 | Successes so far: 57esses: 57\n",
            "Episode 80 | Successes so far: 65cesses: 65\n",
            "Episode 90 | Successes so far: 72esses: 72\n",
            "Episode 100 | Successes so far: 81esses: 81\n",
            "\n",
            "Total successful episodes (score > 200) out of 100: 81\n",
            "Results saved to accuracy_results.csv\n"
          ]
        }
      ],
      "source": [
        "# ====== TRAINING ======\n",
        "number_ep = 2000\n",
        "max_num_timesteps_per_ep = 1000\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 0.995\n",
        "epsilon = epsilon_start\n",
        "scores = deque(maxlen=100)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for episode in range(1, number_ep + 1):\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_num_timesteps_per_ep):\n",
        "        action = agent200.act(state, epsilon)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        agent200.step(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    scores.append(score)\n",
        "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
        "\n",
        "    print('\\rEpisode Number {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores)), end=\"\")\n",
        "    if episode % 100 == 0:\n",
        "        print('\\rEpisode Number {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores)))\n",
        "\n",
        "    if np.mean(scores) >= 200.0:\n",
        "        print('\\nEnvironment solved in {:d} episodes! Episode Number {}\\tAverage Score: {:.2f}'.format(\n",
        "            episode, episode, np.mean(scores)))\n",
        "        torch.save(agent200.local_qnetwork.state_dict(), 'checkpoint_agent200.pth')\n",
        "        break\n",
        "\n",
        "# Save at end even if not solved\n",
        "torch.save(agent200.local_qnetwork.state_dict(), 'checkpoint_agent200.pth')\n",
        "\n",
        "end_time = time.time()\n",
        "train_time_sec = end_time - start_time\n",
        "\n",
        "# ====== TESTING ======\n",
        "agent200.local_qnetwork.load_state_dict(torch.load('checkpoint_agent200.pth'))\n",
        "\n",
        "number_ep = 100\n",
        "scores = []\n",
        "success_count = 0\n",
        "\n",
        "for episode in range(1, number_ep + 1):\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_num_timesteps_per_ep):\n",
        "        action = agent200.act(state, epsilon=0.0)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    scores.append(score)\n",
        "    if score > 200:\n",
        "        success_count += 1\n",
        "\n",
        "    print(f\"\\rEpisode {episode} | Score: {score:.2f} | Successes: {success_count}\", end=\"\")\n",
        "    if episode % 10 == 0:\n",
        "        print(f\"\\rEpisode {episode} | Successes so far: {success_count}\")\n",
        "\n",
        "print(f\"\\nTotal successful episodes (score > 200) out of 100: {success_count}\")\n",
        "\n",
        "with open(\"accuracy_results.csv\", mode=\"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Agent\", \"Train_Time_sec\", \"Test_Success_Count\"])\n",
        "    writer.writerow([\"agent200\", train_time_sec, success_count])\n",
        "\n",
        "print(f\"Results saved to accuracy_results.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode Number 100\tAverage Score: -130.30\n",
            "Episode Number 200\tAverage Score: -68.095\n",
            "Episode Number 300\tAverage Score: 38.001\n",
            "Episode Number 400\tAverage Score: 219.81\n",
            "Episode Number 500\tAverage Score: 248.49\n",
            "Episode Number 600\tAverage Score: 259.35\n",
            "Episode Number 700\tAverage Score: 257.45\n",
            "Episode Number 800\tAverage Score: 255.98\n",
            "Episode Number 900\tAverage Score: 256.56\n",
            "Episode Number 1000\tAverage Score: 271.52\n",
            "Episode Number 1100\tAverage Score: 276.34\n",
            "Episode Number 1200\tAverage Score: 273.74\n",
            "Episode Number 1300\tAverage Score: 274.96\n",
            "Episode Number 1400\tAverage Score: 260.91\n",
            "Episode Number 1500\tAverage Score: 271.49\n",
            "Episode Number 1600\tAverage Score: 276.27\n",
            "Episode Number 1700\tAverage Score: 273.65\n",
            "Episode Number 1800\tAverage Score: 269.98\n",
            "Episode Number 1900\tAverage Score: 271.09\n",
            "Episode Number 2000\tAverage Score: 267.47\n",
            "Episode 10 | Successes so far: 10esses: 10\n",
            "Episode 20 | Successes so far: 18esses: 18\n",
            "Episode 30 | Successes so far: 25esses: 25\n",
            "Episode 40 | Successes so far: 35esses: 35\n",
            "Episode 50 | Successes so far: 43esses: 43\n",
            "Episode 60 | Successes so far: 51sses: 511\n",
            "Episode 70 | Successes so far: 60esses: 60\n",
            "Episode 80 | Successes so far: 67sses: 677\n",
            "Episode 90 | Successes so far: 76esses: 76\n",
            "Episode 100 | Successes so far: 84esses: 84\n",
            "\n",
            "Total successful episodes (score > 200) out of 100: 84\n",
            "Results saved to accuracy_results.csv\n"
          ]
        }
      ],
      "source": [
        "# ====== TRAINING ======\n",
        "number_ep = 2000\n",
        "max_num_timesteps_per_ep = 1000\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 0.995\n",
        "epsilon = epsilon_start\n",
        "scores = deque(maxlen=100)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for episode in range(1, number_ep + 1):\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_num_timesteps_per_ep):\n",
        "        action = agent300.act(state, epsilon)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        agent300.step(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    scores.append(score)\n",
        "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
        "\n",
        "    print('\\rEpisode Number {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores)), end=\"\")\n",
        "    if episode % 100 == 0:\n",
        "        print('\\rEpisode Number {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores)))\n",
        "\n",
        "    if np.mean(scores) >= 300.0:\n",
        "        print('\\nEnvironment solved in {:d} episodes! Episode Number {}\\tAverage Score: {:.2f}'.format(\n",
        "            episode, episode, np.mean(scores)))\n",
        "        torch.save(agent300.local_qnetwork.state_dict(), 'checkpoint_agent300.pth')\n",
        "        break\n",
        "\n",
        "# Save at end even if not solved\n",
        "torch.save(agent300.local_qnetwork.state_dict(), 'checkpoint_agent300.pth')\n",
        "\n",
        "end_time = time.time()\n",
        "train_time_sec = end_time - start_time\n",
        "\n",
        "# ====== TESTING ======\n",
        "agent300.local_qnetwork.load_state_dict(torch.load('checkpoint_agent300.pth'))\n",
        "\n",
        "number_ep = 100\n",
        "scores = []\n",
        "success_count = 0\n",
        "\n",
        "for episode in range(1, number_ep + 1):\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_num_timesteps_per_ep):\n",
        "        action = agent300.act(state, epsilon=0.0)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    scores.append(score)\n",
        "    if score > 200:\n",
        "        success_count += 1\n",
        "\n",
        "    print(f\"\\rEpisode {episode} | Score: {score:.2f} | Successes: {success_count}\", end=\"\")\n",
        "    if episode % 10 == 0:\n",
        "        print(f\"\\rEpisode {episode} | Successes so far: {success_count}\")\n",
        "\n",
        "print(f\"\\nTotal successful episodes (score > 200) out of 100: {success_count}\")\n",
        "\n",
        "with open(\"accuracy_results.csv\", mode=\"a\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"agent300\", train_time_sec, success_count])\n",
        "\n",
        "print(f\"Results saved to accuracy_results.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode Number 100\tAverage Score: -148.09\n",
            "Episode Number 200\tAverage Score: -89.555\n",
            "Episode Number 300\tAverage Score: 27.292\n",
            "Episode Number 400\tAverage Score: 234.69\n",
            "Episode Number 418\tAverage Score: 251.34\n",
            "Environment solved in 418 episodes! Episode Number 418\tAverage Score: 251.34\n",
            "Episode 10 | Successes so far: 10esses: 10\n",
            "Episode 20 | Successes so far: 20esses: 20\n",
            "Episode 30 | Successes so far: 30esses: 30\n",
            "Episode 40 | Successes so far: 40esses: 40\n",
            "Episode 50 | Successes so far: 50esses: 50\n",
            "Episode 60 | Successes so far: 60esses: 60\n",
            "Episode 70 | Successes so far: 70esses: 70\n",
            "Episode 80 | Successes so far: 79esses: 79\n",
            "Episode 90 | Successes so far: 89esses: 89\n",
            "Episode 100 | Successes so far: 99esses: 99\n",
            "\n",
            "Total successful episodes (score > 200) out of 100: 99\n",
            "Results saved to accuracy_results.csv\n"
          ]
        }
      ],
      "source": [
        "# ====== TRAINING ======\n",
        "number_ep = 2000\n",
        "max_num_timesteps_per_ep = 1000\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 0.995\n",
        "epsilon = epsilon_start\n",
        "scores = deque(maxlen=100)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for episode in range(1, number_ep + 1):\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_num_timesteps_per_ep):\n",
        "        action = agent250.act(state, epsilon)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        agent250.step(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    scores.append(score)\n",
        "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
        "\n",
        "    print('\\rEpisode Number {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores)), end=\"\")\n",
        "    if episode % 100 == 0:\n",
        "        print('\\rEpisode Number {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores)))\n",
        "\n",
        "    if np.mean(scores) >= 250.0:\n",
        "        print('\\nEnvironment solved in {:d} episodes! Episode Number {}\\tAverage Score: {:.2f}'.format(\n",
        "            episode, episode, np.mean(scores)))\n",
        "        torch.save(agent250.local_qnetwork.state_dict(), 'checkpoint_agent250.pth')\n",
        "        break\n",
        "\n",
        "# Save at end even if not solved\n",
        "torch.save(agent250.local_qnetwork.state_dict(), 'checkpoint_agent250.pth')\n",
        "\n",
        "end_time = time.time()\n",
        "train_time_sec = end_time - start_time\n",
        "\n",
        "# ====== TESTING ======\n",
        "agent250.local_qnetwork.load_state_dict(torch.load('checkpoint_agent250.pth'))\n",
        "\n",
        "number_ep = 100\n",
        "scores = []\n",
        "success_count = 0\n",
        "\n",
        "for episode in range(1, number_ep + 1):\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    for t in range(max_num_timesteps_per_ep):\n",
        "        action = agent250.act(state, epsilon=0.0)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    scores.append(score)\n",
        "    if score > 200:\n",
        "        success_count += 1\n",
        "\n",
        "    print(f\"\\rEpisode {episode} | Score: {score:.2f} | Successes: {success_count}\", end=\"\")\n",
        "    if episode % 10 == 0:\n",
        "        print(f\"\\rEpisode {episode} | Successes so far: {success_count}\")\n",
        "\n",
        "print(f\"\\nTotal successful episodes (score > 200) out of 100: {success_count}\")\n",
        "\n",
        "with open(\"accuracy_results.csv\", mode=\"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"agent250\", train_time_sec, success_count])\n",
        "\n",
        "print(f\"Results saved to accuracy_results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Agent  Train_Time_sec  Test_Success_Count  Success/TIme\n",
            "0  agent250      291.016522                  99      0.340187\n",
            "1  agent200      282.133176                  81      0.287098\n",
            "2  agent300      895.274564                  84      0.093826\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"accuracy_results.csv\")\n",
        "df[\"Success/TIme\"] = df[\"Test_Success_Count\"]/ df[\"Train_Time_sec\"]\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CUDA_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
